`tokenizer` 主要做三件事：

1. **分词（tokenize）**：把文本拆成 token

2. **转换 ID（encode）**：把 token 变成数字 ID

3. **填充、截断、添加特殊标记**：适配 BERT 输入格式
